{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import sklearn.impute\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import env\n",
    "import acquire\n",
    "import prepare\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'acquire' has no attribute 'get_telco_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d40e616d3bf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_telco_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'acquire' has no attribute 'get_telco_data'"
     ]
    }
   ],
   "source": [
    "df = acquire.get_telco_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train, validate and test\n",
    "X_train, y_train, X_validate, y_validate, X_test, y_test = prepare.split_telco(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.head())\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the relatioship between churn rate and tenure in years\n",
    "plt.figure(figsize=(15,10))\n",
    "ax = sns.lineplot(x=\"tenure_years\", y= \"churn\", data=X_train)\n",
    "plt.title(\"Churn Rate VS Tenure Year\")\n",
    "ax.set_xlabel(\"Tenure Year\")\n",
    "ax.set_ylabel(\"Churn Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaway from Churn Rate VS Tenure Year: Generally speaking, the longer the tenure, the lower the churn rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('partner_and_dependents VS churn rare')\n",
    "ax = sns.barplot(x=\"partner_and_dependents\", y=\"churn\", hue = 'senior_citizen', ci=None, data=X_train)\n",
    "ax.set_ylabel(\"Churn Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaways: It seems custmoers being as senior citizens always have a lower churn rate no matter they have partner and dependent or not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "plt.suptitle('Churn Rate VS Internet Service Type', fontsize=15)\n",
    "\n",
    "plt.subplot(331)\n",
    "ax = sns.barplot(x=\"DSL\", y=\"churn\", ci=None, data=X_train)\n",
    "ax.set_ylabel(\"Churn Rate\")\n",
    "plt.ylim(0, .5)\n",
    "\n",
    "plt.subplot(332)\n",
    "ax = sns.barplot(x=\"Fiber optic\", y=\"churn\", ci=None, data=X_train)\n",
    "ax.set_ylabel(\"Churn Rate\")\n",
    "plt.ylim(0, .5)\n",
    "\n",
    "plt.subplot(333)\n",
    "ax = sns.barplot(x=\"None\", y=\"churn\", ci=None, data=X_train)\n",
    "ax.set_ylabel(\"Churn Rate\")\n",
    "plt.ylim(0, .5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeways: Comparing with other internet service, Fiber optic has the highest churn rate, while None internet service has the lowest churn rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "### T_Test for Tenure vs Churn\n",
    "$H_0$: there is no difference in tenure between customers who are still with telco and who have churned\n",
    "\n",
    "$H_a$: there is a difference in tenure between customers who are still with telco and who have churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since churn is a categorical variable, and tenure_years is a continous variable, use T-Test\n",
    "alpha = 0.05\n",
    "x1 = X_train[X_train.churn == 1].tenure_years\n",
    "x2 = X_train[X_train.churn == 0].tenure_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstat, p = stats.ttest_ind(x1, x2)\n",
    "tstat, p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "Because p ({p:.4f}) < alpha (0.05), reject the null hypothesis, which means there is a statistically significant\n",
    "diffrence in tenure between customers who are still with telco and who have churned.\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train.groupby('churn').tenure_years.mean().plot.bar()\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Average tenure in years')\n",
    "plt.title('Is tenure different among customers who are churned or not?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson's correlation coefficient test\n",
    "\n",
    "ð»0 : There is no linear correlation between monthly charges and Fiber optic(one type of internent service)\n",
    "\n",
    "ð»ð‘Ž:  There is a linear correlation between monthly charges and Fiber optic(one type of internent service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set alpha value to .01\n",
    "alpha = .01 \n",
    "r, p = stats.pearsonr(X_train.monthly_charges, X_train['Fiber optic'])\n",
    "\n",
    "if p < alpha:\n",
    "    print(\"Reject the null hypothesis\")\n",
    "\n",
    "else:\n",
    "    print(\"Fail to reject our null hypothesis\")\n",
    "\n",
    "print(\"R is\", r)\n",
    "print(\"p is\", p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaways: There is a strong linear correlation between monthly charges and Fiber optic(one type of internent service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi squared test\n",
    "\n",
    "Since vast majority variables in the dataset are categorical variables, here it would be great to apply the Chi squared test for testing independence between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set alpha value\n",
    "alpha = 0.05\n",
    "\n",
    "for col in X_train.columns:\n",
    "\n",
    "    a, b = X_train[col], X_train[\"churn\"]\n",
    "\n",
    "    observed = pd.crosstab(a, b) \n",
    "    chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "    if p < alpha:\n",
    "        # Reject the null hypothesis\n",
    "        print(\"({} and churn) are  dependent of each other. (p = {})\".format(col, p))\n",
    "    else:\n",
    "         # Failed to reject the null hypothesis\n",
    "        print(\"({} and churn) are  independent of each other. (p = {})\".format(col, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaways: Vast majority of variables are dependent with churn, except gender and total_charges are independent with churn respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cramer's V is a statistic used to measure the strength of association between two nominal variables, \n",
    "# and it take values from 0 to 1. Values close to 0 indicate a weak association between the variables\n",
    "# and values close to 1 indicate a strong association between the variables.\n",
    "import itertools\n",
    "def cramers_corrected_stat(confusion_matrix):\n",
    "    \"\"\"\n",
    "    Calculates the corrected Cramer's V statistic\n",
    "    \n",
    "    Args:\n",
    "        confusion_matrix: The confusion matrix of the variables to calculate the statistic on\n",
    "    \n",
    "    Returns:\n",
    "        The corrected Cramer'v V statistic\n",
    "    \"\"\"\n",
    "    \n",
    "    chi2, _, _, _ = stats.chi2_contingency(confusion_matrix)\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2/n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))    \n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    \n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "cols = list(X_train.columns.values)\n",
    "corrM = np.zeros((len(cols),len(cols)))\n",
    "\n",
    "# Calculate s of every combination of variables\n",
    "for col1, col2 in itertools.combinations(cols, 2):\n",
    "\n",
    "    a, b = X_train[col1], X_train[col2]\n",
    "    \n",
    "    idx1, idx2 = cols.index(col1), cols.index(col2)\n",
    "    dfObserved = pd.crosstab(a,b) \n",
    "    corrM[idx1, idx2] = cramers_corrected_stat(dfObserved.values)\n",
    "    corrM[idx2, idx1] = corrM[idx1, idx2]\n",
    "\n",
    "corr = pd.DataFrame(corrM, index=cols, columns=cols)\n",
    "\n",
    "# Mask to get lower triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask \n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n",
    "plt.title('Cramerâ€™s V calculated for the telco churn dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaway from the above heatmap: Except gender and total_charges, all features have some kind of association with churn, although all of the associations are not strong. Nevertheless, the strongest association exists between Month_to_month(contract_type) and tenure, the Cramer's V value is 0.41."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['churn'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate = X_validate.drop(['churn'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['churn'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred = model.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(y_validate, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.drop(['gender','total_charges'],axis=1)\n",
    "#X_validate = X_validate.drop(['gender','total_charges'],axis=1)\n",
    "# model = LogisticRegression().fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=123)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(y_validate, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(min_samples_leaf=5, max_depth=10,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(y_validate, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_report(y_validate, y_pred, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
